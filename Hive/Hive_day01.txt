$hivehive> create database sqoop_import;ok
hive>dfs –ls /user/hive/warehouse;        will see a scoop_import.db in this warehousehive> CREATE TABLE IF NOT EXISTS employee ( eid int, name String,
salary String, destination String)
COMMENT ‘Employee details’
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ‘\t’
LINES TERMINATED BY ‘\n’
STORED AS TEXTFILE;


OK
default
employee
sqoop_import
user
userdb
Time taken: 0.109 seconds, Fetched: 5 row(s)

The following queries are used to drop a database. Let us assume that the database name is userdb.

hive> DROP DATABASE IF EXISTS userdb;
The following query drops the database using CASCADE. It means dropping respective tables before dropping the database.

hive> DROP DATABASE IF EXISTS userdb CASCADE;
The following query drops the database using SCHEMA.

hive> DROP SCHEMA userdb;

hive> ALTER TABLE employee RENAME TO emp;

Hive organizes tables into partitions. It is a way of dividing a table into related parts based on the values of partitioned columns such as date, city, and department. Using partition, it is easy to query a portion of the data.

Tables or partitions are sub-divided into buckets, to provide extra structure to the data that may be used for more efficient querying. Bucketing works based on the value of hash function of some column of a table.

/tab1/employeedata/file1

id, name, dept, yoj
1, gopal, TP, 2012
2, kiran, HR, 2012
3, kaleel,SC, 2013
4, Prasanth, SC, 2013

The above data is partitioned into two files using year.

/tab1/employeedata/2012/file2

1, gopal, TP, 2012
2, kiran, HR, 2012

/tab1/employeedata/2013/file3

3, kaleel,SC, 2013
4, Prasanth, SC, 2013

Consider default database available in hive and one sample_07 table
hive>select * from sample_07
hive>create table toodey1(code string,salary int);
hive>create table toodey2(code string,salary string);
hive>create table toodey3(total_emp int,salary int);

hive>quit;

//will copy all retail_db tables into hive
$sqoop import-all-tables \
  --num-mappers 1 \
  --connect "jdbc:mysql://quickstart.cloudera:3306/retail_db" \
  --username=retail_dba \
  --password=cloudera \
  --hive-import \
  --hive-overwrite \
  --create-hive-table \
  --compress \
  --compression-codec org.apache.hadoop.io.compress.SnappyCodec \
  --outdir java_files

hive>pdfs -ls /user/hive/warehouse
categories
customers
user.db
userdb.dbdrop